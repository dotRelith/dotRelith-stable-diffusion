{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dotRelith/even-faster-stable-diffusion/blob/main/even-faster-stable-diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83PZepZYu4sE"
      },
      "source": [
        "# **Even Faster Stable Diffusion** by [dotRelith](https://github.com/dotRelith/even-faster-stable-diffusion)\n",
        "**Step-By-Step Guide:**\n",
        "*   First-time Installation\n",
        "  1.   Mount Google Drive\n",
        "  2.   Install AUTOMATIC1111-web-ui\n",
        "  3.   MODEL DOWNLOAD/LOAD\n",
        "  4.   Start AUTOMATIC1111-web-ui\n",
        "\n",
        "*   Subsequent Installations\n",
        "  1.   Mount Google Drive\n",
        "  2.   MODEL DOWNLOAD/LOAD\n",
        "  3.   Start AUTOMATIC1111-web-ui\n",
        "\n",
        "Note: If you have enough space in your google drive you can put your own models inside the default folder (/content/gdrive/MyDrive/stable-diffusion-webui/models/Stable-diffusion) that everything will work normally.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQTCSyjv9m0y"
      },
      "source": [
        "**IMPORTANT FOR BEGGINERS**<br>\n",
        "To execute the code in Colab, follow the arrow in the image and click on the designated area. You will need to repeat this process for each code block that you want to run. If you are unsure of which blocks to run, refer to the **step-by-step guide** for guidance.\n",
        "<br>\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjFESYlElbUR",
        "outputId": "c41536ba-ec64-4f30-ef84-ad804efb2876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDEPENDENCIES INSTALLED!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Mount Google Drive\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "from google.colab import drive\n",
        "from google.colab import output\n",
        "from subprocess import getoutput\n",
        "import os\n",
        "import time\n",
        "import fileinput\n",
        "import sys\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "print('\u001b[1;32mINSTALLING DEPENDENCIES\\033[0m')\n",
        "!pip install -q -U --pre triton\n",
        "!pip install -q accelerate==0.12.0 transformers ftfy bitsandbytes protobuf==3.19.5 natsort open_clip_torch gradio==3.15.0\n",
        "!pip install -q https://github.com/brian6091/xformers-wheels/releases/download/0.0.15.dev0%2B4c06c79/xformers-0.0.15.dev0+4c06c79.d20221205-cp38-cp38-linux_x86_64.whl\n",
        "clear_output()\n",
        "print('\u001b[1;32mDEPENDENCIES INSTALLED!\\033[0m')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-hwjRLRgl1t8"
      },
      "outputs": [],
      "source": [
        "#@markdown # Check GPU\n",
        "#@markdown (Just for curiosity)\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "w3xQ1PhpmEjN"
      },
      "outputs": [],
      "source": [
        "#@markdown # Install AUTOMATIC1111-web-ui\n",
        "#markdown > Stable Diffusion github repo was suspended, you'll have to redownload Stable Diffusion fow you to get latest version.<br>I suggest that you delete the old files.\n",
        "\n",
        "#!git clone https://gitgud.io/AUTOMATIC1111/stable-diffusion-webui.git /content/gdrive/MyDrive/stable-diffusion-webui\n",
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui.git /content/gdrive/MyDrive/stable-diffusion-webui\n",
        "!wget --no-check-certificate --content-disposition -P /content/gdrive/MyDrive/stable-diffusion-webui/textual_inversion_templates https://github.com/dotRelith/AUTOMATIC1111-web-ui-extra-files/raw/main/textual_inversion_templates/subject_female.txt\n",
        "!wget --no-check-certificate --content-disposition -P /content/gdrive/MyDrive/stable-diffusion-webui/textual_inversion_templates https://github.com/dotRelith/AUTOMATIC1111-web-ui-extra-files/raw/main/textual_inversion_templates/subject_female_filewords.txt\n",
        "!wget --no-check-certificate --content-disposition -P /content/gdrive/MyDrive/stable-diffusion-webui/textual_inversion_templates https://github.com/dotRelith/AUTOMATIC1111-web-ui-extra-files/raw/main/textual_inversion_templates/subject_male.txt\n",
        "!wget --no-check-certificate --content-disposition -P /content/gdrive/MyDrive/stable-diffusion-webui/textual_inversion_templates https://github.com/dotRelith/AUTOMATIC1111-web-ui-extra-files/raw/main/textual_inversion_templates/subject_male_filewords.txt\n",
        "!echo \"/textual_inversion_templates\" >> .gitignore\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDONE!\\033[0m')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kauowrfL5d30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8fdfefb-9170-4442-9e1f-4cdf2abceb52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mALL MODELS DOWNLOADED!\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@markdown # Model Download/Load\n",
        "#@markdown ---\n",
        "#@markdown > Change this if you want to use another path to store all your models(.ckpt files).<br>( Leave empty to use Colab HardDrive )\n",
        "CKPT_directory_path = '' #@param {type:\"string\"}\n",
        "#@markdown > Path to the CKPT you want to load in by default<br>( Include .ckpt at the end )<br>(Ex: \"/content/models/v1-5-pruned.ckpt\")\n",
        "default_CKPT_name = '' #@param {type:\"string\"}\n",
        "#@markdown ---\n",
        "#@markdown > Common Models to download.<br>(Check boxes to download)\n",
        "AnythingV3 = True #@param {type:\"boolean\"}\n",
        "StableDiffusion_v1_5 = False #@param {type:\"boolean\"}\n",
        "StableDiffusion_v2_1 = False #@param {type:\"boolean\"}\n",
        "WaifuDiffusion_v1_3 = False #@param {type:\"boolean\"}\n",
        "WaifuDiffusion_v1_4 = False #@param {type:\"boolean\"}\n",
        "OpenJourney_v4 = False #@param {type:\"boolean\"}\n",
        "#@markdown > Use last downloaded model as default?\n",
        "UseLastDownloadedAsDefault = True #@param {type:\"boolean\"}\n",
        "#@markdown ---\n",
        "#@markdown > Direct model link<br>(Leave empty to ignore)\n",
        "FirstCustomModel = '' #@param {type:\"string\"}\n",
        "SecondCustomModel = '' #@param {type:\"string\"}\n",
        "ThirdCustomModel = '' #@param {type:\"string\"}\n",
        "\n",
        "if CKPT_directory_path == '':\n",
        "  CKPT_directory_path = '/content/models'\n",
        "  if not os.path.exists(CKPT_directory_path):\n",
        "    os.makedirs(CKPT_directory_path)\n",
        "\n",
        "if default_CKPT_name != '':\n",
        "  default_CKPT_name = \"--ckpt \" + default_CKPT_name\n",
        "\n",
        "%cd \"$CKPT_directory_path\"\n",
        "\n",
        "def download_model(model_url, name=None):\n",
        "  global default_CKPT_name\n",
        "  file_name = model_url.rsplit('/', 1)[-1]\n",
        "  if name is not None:\n",
        "    extension = file_name.rsplit('.', 1)[-1]\n",
        "    if extension == \"pt\":\n",
        "      extension = \"vae.pt\"\n",
        "    file_name = f\"{name}.{extension}\"    \n",
        "  if UseLastDownloadedAsDefault:\n",
        "    if file_name.rsplit('.', 1)[-1] == \"ckpt\" or file_name.rsplit('.', 1)[-1] == \"safetensors\":\n",
        "      default_CKPT_name = f\"--ckpt {CKPT_directory_path}/{file_name}\"\n",
        "  if not os.path.exists(f\"{CKPT_directory_path}/{file_name}\"):\n",
        "    !wget \"$model_url\" -O \"$file_name\"\n",
        "\n",
        "if AnythingV3:\n",
        "  download_model(\"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0.vae.pt\",\"Anything-V3.0\")\n",
        "  download_model(\"https://huggingface.co/Linaqruf/anything-v3.0/resolve/main/Anything-V3.0-pruned.ckpt\",\"Anything-V3.0\")\n",
        "if StableDiffusion_v1_5:\n",
        "  download_model(\"https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned.ckpt\",\"stable_diffusion_v1_5\")\n",
        "if StableDiffusion_v2_1:\n",
        "  download_model(\"https://raw.githubusercontent.com/Stability-AI/stablediffusion/main/configs/stable-diffusion/v2-inference-v.yaml\",\"stable_diffusion_v2_1\")\n",
        "  download_model(\"https://huggingface.co/stabilityai/stable-diffusion-2-1/resolve/main/v2-1_768-ema-pruned.safetensors\",\"stable_diffusion_v2_1\")\n",
        "if WaifuDiffusion_v1_3:\n",
        "  download_model(\"https://huggingface.co/hakurei/waifu-diffusion-v1-3/resolve/main/wd-v1-3-full.ckpt\",\"waifu_diffusion_v1_3\")\n",
        "if WaifuDiffusion_v1_4:\n",
        "  download_model(\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/raw/main/wd-1-4-anime_e1.yaml\",\"waifu_diffusion_v1_4\")\n",
        "  download_model(\"https://huggingface.co/hakurei/waifu-diffusion-v1-4/resolve/main/wd-1-4-anime_e1.ckpt\",\"waifu_diffusion_v1_4\")\n",
        "if OpenJourney_v4:\n",
        "  download_model(\"https://huggingface.co/prompthero/openjourney/resolve/main/mdjrny-v4.ckpt\")\n",
        "if FirstCustomModel:\n",
        "  download_model(FirstCustomModel)\n",
        "if SecondCustomModel:\n",
        "  download_model(SecondCustomModel)\n",
        "if ThirdCustomModel:\n",
        "  download_model(ThirdCustomModel)\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mALL MODELS DOWNLOADED!\\033[0m')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 882
        },
        "id": "3tf1QDeRn1xP",
        "outputId": "bb84056e-31a9-4078-ce0a-f40c1d8a7f9b",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mSERVER CONFIG DEPLOYED!\u001b[0m\n",
            "/content/gdrive/MyDrive/stable-diffusion-webui\n",
            "Python 3.8.16 (default, Dec  7 2022, 01:12:13) \n",
            "[GCC 7.5.0]\n",
            "Commit hash: ff6a5bcec1ce25aa8f08b157ea957d764be23d8d\n",
            "Installing requirements for Web UI\n",
            "\n",
            "#######################################################################################################\n",
            "Initializing Dreambooth\n",
            "If submitting an issue on github, please provide the below text for debugging purposes:\n",
            "\n",
            "Python revision: 3.8.16 (default, Dec  7 2022, 01:12:13) \n",
            "[GCC 7.5.0]\n",
            "Dreambooth revision: 17c3864803ebb50615205271de687be96cfc96e8\n",
            "SD-WebUI revision: ff6a5bcec1ce25aa8f08b157ea957d764be23d8d\n",
            "\n",
            "Checking Dreambooth requirements...\n",
            "[+] bitsandbytes version 0.35.0 installed.\n",
            "[+] diffusers version 0.10.2 installed.\n",
            "[+] transformers version 4.25.1 installed.\n",
            "[+] xformers version 0.0.15.dev0+4c06c79.d20221205 installed.\n",
            "[+] torch version 1.13.0+cu116 installed.\n",
            "[+] torchvision version 0.14.0+cu116 installed.\n",
            "\n",
            "#######################################################################################################\n",
            "\n",
            "Launching Web UI with arguments: --enable-insecure-extension-access --xformers --ckpt-dir /content/models --ckpt /content/models/Anything-V3.0.ckpt --deepdanbooru --precision full --no-half\n",
            "2023-01-16 00:57:46.070988: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-01-16 00:57:47.304874: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-01-16 00:57:47.305175: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.8/dist-packages/cv2/../../lib64:/usr/lib64-nvidia\n",
            "2023-01-16 00:57:47.305210: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "SD-Webui API layer loaded\n",
            "LatentDiffusion: Running in eps-prediction mode\n",
            "DiffusionWrapper has 859.52 M params.\n",
            "Downloading: 100% 961k/961k [00:00<00:00, 5.72MB/s]\n",
            "Downloading: 100% 525k/525k [00:00<00:00, 3.60MB/s]\n",
            "Downloading: 100% 389/389 [00:00<00:00, 452kB/s]\n",
            "Downloading: 100% 905/905 [00:00<00:00, 808kB/s]\n",
            "Downloading: 100% 4.52k/4.52k [00:00<00:00, 4.93MB/s]\n",
            "Loading weights [543bcbc212] from /content/models/Anything-V3.0.ckpt\n",
            "Loading VAE weights found near the checkpoint: /content/models/Anything-V3.0.vae.pt\n",
            "Applying xformers cross attention optimization.\n",
            "Textual inversion embeddings loaded(0): \n",
            "Model loaded in 32.8s (2.5s create model, 29.0s load weights).\n",
            "Running on local URL:  https://clear-mails-serve-35-188-140-242.loca.lt:443\n",
            "\u001b[32mConnected\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Start AUTOMATIC1111-web-ui\n",
        "#@markdown --- \n",
        "#@markdown <br>\n",
        "#@markdown <center> You will hear a <b>quack</b> when the notebook is about to start</center>\n",
        "\n",
        "#@markdown > ALL CREDITS TO '[TheLastBen](https://github.com/TheLastBen)' for the 'Use_LocalTunnel' code\n",
        "Use_LocalTunnel = True #@param {type:\"boolean\"}\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  if not os.path.exists('/tools/node/bin/lt'):\n",
        "    !npm install -g localtunnel\n",
        "\n",
        "with capture.capture_output() as cap:\n",
        "  %cd /content/gdrive/MyDrive/stable-diffusion-webui/\n",
        "  !git reset --hard\n",
        "  !git pull\n",
        "  time.sleep(5)\n",
        "  clear_output()\n",
        "  print('\u001b[1;32mUPDATE !')\n",
        "  !sed -i 's@ui.create_ui().*@ui.create_ui();shared.demo.queue(concurrency_count=999999,status_update_rate=0.1)@' /content/gdrive/MyDrive/stable-diffusion-webui/webui.py\n",
        "  !sed -i \"s@os.path.splitext(checkpoint_file)@os.path.splitext(checkpoint_file); map_location='cuda' if os.path.getsize(checkpoint_file) > 5500000000 else map_location@\" /content/gdrive/MyDrive/stable-diffusion-webui/modules/sd_models.py\n",
        "  !sed -i \"s@map_location='cpu'@map_location='cuda'@\" /content/gdrive/MyDrive/stable-diffusion-webui/modules/extras.py\n",
        "  !sed -i 's@min-height: 4.*@min-height: 5.5em;@g' /content/gdrive/MyDrive/stable-diffusion-webui/style.css\n",
        "  !sed -i 's@\"multiple_tqdm\": true,@\\\"multiple_tqdm\": false,@' /content/gdrive/MyDrive/stable-diffusion-webui/config.json\n",
        "  !sed -i '902s@.*@        self.logvar = self.logvar.to(self.device)@' /content/gdrive/MyDrive/stable-diffusion-webui/ldm/models/diffusion/ddpm.py\n",
        "\n",
        "share=''\n",
        "if not Use_LocalTunnel:\n",
        "  share='--share'\n",
        "  for line in fileinput.input('/usr/local/lib/python3.8/dist-packages/gradio/blocks.py', inplace=True):\n",
        "    if line.strip().startswith('self.server_name ='):\n",
        "        line = '            self.server_name = server_name\\n'\n",
        "    if line.strip().startswith('self.server_port ='):\n",
        "        line = '            self.server_port = server_port\\n'\n",
        "    sys.stdout.write(line)\n",
        "  clear_output()\n",
        "else:\n",
        "  with capture.capture_output() as cap:\n",
        "    share=''\n",
        "    %cd /content\n",
        "    !nohup lt --port 7860 > srv.txt 2>&1 &\n",
        "    time.sleep(2)\n",
        "    !grep -o 'https[^ ]*' /content/srv.txt >srvr.txt\n",
        "    time.sleep(2)\n",
        "    srv= getoutput('cat /content/srvr.txt')\n",
        "\n",
        "    for line in fileinput.input('/usr/local/lib/python3.8/dist-packages/gradio/blocks.py', inplace=True):\n",
        "      if line.strip().startswith('self.server_name ='):\n",
        "          line = f'            self.server_name = \"{srv[8:]}\"\\n'\n",
        "      if line.strip().startswith('self.server_port ='):\n",
        "          line = '            self.server_port = 443\\n'\n",
        "      if line.strip().startswith('self.protocol = \"https\"'):\n",
        "          line = '            self.protocol = \"https\"\\n'\n",
        "      if line.strip().startswith('if self.local_url.startswith(\"https\") or self.is_colab'):\n",
        "          line = ''\n",
        "      if line.strip().startswith('else \"http\"'):\n",
        "          line = ''\n",
        "      sys.stdout.write(line)\n",
        "            \n",
        "    !sed -i '13s@.*@    \"PUBLIC_SHARE_TRUE\": \"\u001b[32mConnected\\\\033[0m\",@' /usr/local/lib/python3.8/dist-packages/gradio/strings.py\n",
        "\n",
        "    !rm /content/srv.txt\n",
        "    !rm /content/srvr.txt\n",
        "\n",
        "if os.path.exists('/content/gdrive/MyDrive/stable-diffusion-webui/extensions/sd_dreambooth_extension'):\n",
        "  !pip install /content/gdrive/MyDrive/stable-diffusion-webui/extensions/sd_dreambooth_extension/requirements.txt\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mSERVER CONFIG DEPLOYED!\\033[0m')\n",
        "\n",
        "%cd /content/gdrive/MyDrive/stable-diffusion-webui/\n",
        "output.eval_js('new Audio(\"https://cdn.pixabay.com/download/audio/2022/03/10/audio_5adfa08633.mp3?filename=075176_duck-quack-40345.mp3\").play()')\n",
        "performance_args = \"--opt-split-attention\"\n",
        "!python launch.py --enable-insecure-extension-access --xformers --ckpt-dir \"$CKPT_directory_path\" $default_CKPT_name --deepdanbooru --precision full --no-half $share"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}